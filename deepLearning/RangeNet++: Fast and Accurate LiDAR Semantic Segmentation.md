## [RangeNet++: Fast and Accurate LiDAR Semantic Segmentation](http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/milioto2019iros.pdf)

github: [lidar-bonnetal](https://github.com/PRBonn/lidar-bonnetal)

## 概要

+ 最近の傾向として、高解像度カメラによるセマンティックの解決が多い。そのため、他のセンサモダリティが無視されがち。
+ LiDARのみのセマンティックセグメンテーションの最新技術を提供
+ 回転するLiDARのセンサモデルを説明するCNNと組み合わせて中間画像表現として距離画像を用いる
+ 実際の自動運転に耐えうる正確性と高速性を持つLiDARにおけるセマンティックセグメンテーション

## 提案

離散化エラーや分散が大きいCNN出力など、中間表現から生じる問題を処理する新しい後処理アルゴリズムを提案

## 手法

入力点群の球面投影(距離画像ライクな3D画像表現)を用いた。この投影画像の各ピクセルのセグメンテーションを推定する。
しかし、このアプローチの結果、離散化またはぼやけたCNN出力に起因する問題につながる可能性がある。
(ぼやけた出力 砂時計型のエンコーダ/デーコーダーのCNNモデルを使用しているため)
画像ベースのCNNの解像度の使用に関係なく、セマンティックスされたもとの点の再構築に解決する。

# 詳細な処理の流れ

1. 入力点群から距離画像表現へ変更
   Pi = (x, y, z)を球面座標に変換し、最後に画像座標(u,v)に変換。(h, w)は目的範囲の画像表現の高さと幅です。
2. 2D畳み込みセマンティックセグメンテーション
   砂時計型のエンコーダーを使用。最後は、ソフトマックス。
3. 2Dから3D へセマンティックを変換
4. k-Nearest-Neighbor(kNN)検索を使用して、出力のぼやけを対処。kNN探索の高速化が本手法の大きな提案部分。



